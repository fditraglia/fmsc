%!TEX root = main.tex
\section{Introduction}
In finite samples, the addition of a slightly endogenous but highly relevant instrument can reduce estimator variance by far more than bias is increased. 
Building on this observation, I propose a novel moment selection criterion for generalized method of moments (GMM) estimation: the focused moment selection criterion (FMSC). 
Rather than selecting only valid moment conditions, the FMSC chooses from a set of potentially mis-specified moment conditions based on the asymptotic mean squared error (AMSE) of their associated GMM estimators of a user-specified scalar target parameter.
To ensure a meaningful bias-variance tradeoff in the limit, I employ a drifting asymptotic framework in which mis-specification, while present for any fixed sample size, vanishes asymptotically.
In the presence of such \emph{locally mis-specified} moment conditions, GMM remains consistent although, centered and rescaled, its limiting distribution displays an asymptotic bias. Adding an additional mis-specified moment condition introduces a further source of bias while reducing asymptotic variance. 
The idea behind the FMSC is to trade off these two effects in the limit as an approximation to finite sample behavior.\footnote{When finite-sample mean-squared error (MSE) is undefined or infinite, AMSE comparisons remain meaningful. In this case, one can view AMSE as the limit of a sequence of ``trimmed'' squared error loss functions, as in \cite{Hansen2013}. Trimmed MSE is always well-defined and the trimming fraction can be made asymptotically negligible.}
 
I consider a setting in which two blocks of moment conditions are available: one that is assumed correctly specified, and another that may not be.
This is intended to mimic the situation faced by an applied researcher who begins with a ``baseline'' set of relatively weak maintained assumptions and must decide whether to impose any of a collection of stronger but also more controversial ``suspect'' assumptions.
When the (correctly specified) baseline moment conditions identify the model, the FMSC provides an asymptotically unbiased estimator of AMSE, allowing us to carry out risk-based selection over the suspect moment conditions.
When this is not the case, it remains possible to use the AMSE framework to carry out a sensitivity analysis.\footnote{For discussion of this point, see Appendix \ref{sec:digress}.}

I go on to study a general class estimators formed by combining estimators based on different moment sets with data-dependent weights.
Such ``moment average'' estimators are interesting in their own right and can be used to study the important problem of inference post-selection.
By deriving the limiting distribution of the class of moment average estimators, I devise a simple, simulation-based procedure for constructing valid confidence intervals that can be applied to a variety of formal moment averaging and post-selection estimators.
Using an applied example from development economics, I show that this procedure is well within the ability of a standard desktop computer for problems of a realistic scale.

While the methods described here apply to general GMM models, I focus on two simple but empirically relevant examples: choosing between ordinary least squares (OLS) and two-stage least squares (TSLS) estimators, and selecting instruments in linear instrumental variables (IV) models. 
In the OLS versus TSLS example the FMSC takes a particularly transparent form, providing a risk-based justification for the DHW test, and leading to a novel ``minimum-AMSE'' estimator that combines the information contained in the OLS and TSLS estimators.
It is important to note that both the FMSC and related minimum-AMSE averaging estimator considered here are derived for a \emph{scalar} parameter of interest, as this is the most common situation encountered in applied work.
As a consequence, Stein-type results do \emph{not} apply: it is impossible to construct an estimator -- post-selection, averaging or otherwise -- with uniformly lower risk than the ``valid'' estimator that uses only the baseline moment conditions in estimation.
Nevertheless, it remains possible to achieve substantially lower risk than the valid estimator over large regions of the parameter space, particularly in settings where the additional moment conditions are \emph{nearly} correct.
This is precisely the situation for which the FMSC is designed.
Selection and averaging are not a panacea, but in settings where the suspect moment conditions are expected to be at least approximately correct \emph{a priori}, the methods presented in this paper can provide substantial gains, as demonstrated in the simulation results presented below.

My approach to moment selection is inspired by the focused information criterion of \citet{ClaeskensHjort2003}, a model selection criterion for maximum likelihood estimation. 
Like \citet{ClaeskensHjort2003}, I study AMSE-based selection under mis-specification in a drifting asymptotic framework. 
In contradistinction, however, I consider moment rather than model selection, and general GMM rather than maximum likelihood estimation.
Although developed independently of the FIC, \cite{Schorfheide2005} uses a similar approach to select over forecasts constructed from mis-specified vector autoregression models.
Mine is by no means the first paper to consider GMM asymptotics under locally mis-specified moment conditions, an idea that dates at least as far back as \cite{Newey1985}.
The idea of using this framework for AMSE-based moment selection, however, is novel.

The existing literature on moment selection under mis-specification is primarily concerned with consistent selection: the goal is to select all correctly specified moment conditions while eliminating all invalid ones with probability approaching one in the limit.\footnote{Under the local mis-specification asymptotics considered below, consistent moment selection criteria simply choose \emph{all} available moment conditions. For details, see Theorem \ref{pro:andrews}.}
This idea begins with \cite{Andrews1999} and is extended by  \cite{AndrewsLu} and \cite{HongPrestonShum}.
More recently, \cite{Liao} proposes a shrinkage procedure for consistent GMM moment selection and estimation. 
In contrast to these proposals, which examine only the validity of the moment conditions under consideration, the FMSC balances validity against relevance to minimize AMSE.
Although \cite{HallPeixe2003} and \cite{ChengLiao} do consider relevance, their aim is to avoid including redundant moment conditions after consistently eliminating invalid ones.
Some other papers that propose choosing, or combining, instruments to minimize MSE include \cite{DonaldNewey2001}, \cite{DonaldImbensNewey2009}, and \cite{KuersteinerOkui2010}.
Unlike the FMSC, however, these proposals consider the \emph{higher-order} bias that arises from including many valid instruments rather than the first-order bias that arises from the use of invalid instruments.

Another important difference between the FMSC and the other proposals from the literature is the ``F'' -- focus: rather than a single moment selection criterion, the FMSC is really a method of constructing application-specific moment selection criteria.
To see the potential benefits of this approach consider, for example, a simple dynamic panel model.
If your target parameter is a long-run effect while mine is a contemporaneous effect, there is no reason to suppose \emph{a priori} that we should use the same moment conditions in estimation, even if we share the same model and dataset.
The FMSC explicitly takes this difference of research goals into account.

Like Akaike's Information Criterion (AIC), the FMSC is a \emph{conservative} rather than consistent selection procedure, as it \emph{remains random} even in the limit.	
Although consistency is a crucial minimal property in many settings, the situation is more complex for model and moment selection: consistent and conservative selection procedures have different strengths, but these strengths cannot be combined \citep{Yang2005}.
The motivation behind the FMSC is minimum-risk estimation.
From this perspective, consistent selection criteria suffer from a serious defect: in general, unlike conservative criteria, they exhibit \emph{unbounded} minimax risk \citep{LeebPoetscher2008}.
Moreover, as discussed in more detail below, the asymptotics of consistent selection paint a misleading picture of the effects of moment selection on inference.
For these reasons, the fact that the FMSC is conservative rather than consistent is an asset in the present context.

Because it studies inference post-moment selection, this paper relates to a vast literature on ``pre-test'' estimators.
For an overview, see \citet{LeebPoetscher2005, LeebPoetscher2009}.
There are several proposals to construct valid confidence intervals post-model selection, including \cite{Kabaila1998}, \cite{HjortClaeskens} and \cite{KabailaLeeb2006}. 
To my knowledge, however, this is the first paper to treat the problem in general for post-moment selection and moment average estimators in the presence of mis-specification.\footnote{Related results appear in \cite{Berkowitz}, \cite{Guggenberger2010}, \cite{Guggenberger2012}, and \cite{GuggenbergerKumar}.}
While I developed the simulation-based, two-stage confidence interval procedure described below by analogy to a suggestion in \cite{ClaeskensHjortbook}, \cite{Leeb} kindly pointed out that similar constructions have appeared in \cite{Loh1985}, \cite{Berger1994}, and \cite{Silvapulle1996}. More recently, \cite{McCloskey} takes a similar approach to study a class of non-standard testing problems.

The framework within which I study moment averaging is related to the frequentist model average estimators of \cite{HjortClaeskens}.
Two other papers that consider weighting estimators based on different moment conditions are \cite{Xiao} and \cite{ChenChavezLinton}.
Whereas these papers combine estimators computed using valid moment conditions to achieve a minimum variance estimator, I combine estimators computed using potentially invalid conditions with the aim of reducing estimator AMSE.
A similar idea uderlies the combined moments (CM) estimator of \cite{Judge2007}, who emphasize that incorporating the information from an incorrect specification could lead to favorable bias-variance tradeoff. 
Unlike the FMSC, however, the CM estimator is not targeted to a particular research goal and does not explicitly aim to minimize AMSE.
For a different approach to combining OLS and TSLS estimators, similar in spirit to the Stein-estimator and developed independently of the work presented here, see \cite{Hansen2014}. 
\cite{ChengLiaoShi} provide related results for Stein-type moment averaging in a GMM context with potentially mis-specified moment conditions.
Both of these papers consider settings in which the parameter of interest is of sufficiently high dimension that averaging can yield uniform risk improvements.
In contrast, I consider a setting with a scalar target parameter in which uniform improvements are unavailable.

A limitation of the results presented here is that they are based upon the assumption of strong identification and a fixed number of moment conditions.
When I refer to a bias-variance tradeoff below, either in finite samples or asymptotically, I abstract from weak-- and many--instruments considerations.
In particular, my asymptotics are based on a classical first-order approximation with the addition of locally invalid moment conditions.
Extending the idea behind the FMSC to allow for weak identification or a large number of moment conditions is a challenging topic that I leave for future research.

The remainder of the paper is organized as follows.
Section \ref{sec:asymp} describes the asymptotic framework and Section \ref{sec:FMSC} derives the FMSC, both in general and for two specific examples: OLS versus TSLS and choosing instrumental variables.
Section \ref{sec:avg} studies moment average estimators and shows how they can be used to construct valid confidence intervals post-moment selection.
Section \ref{sec:simulations} presents simulation results and Section \ref{sec:application} considers an empirical example from development economics.
Proofs, computational details and supplementary material appear in the Appendix. 
