#Frank DiTraglia
#February 21st 2014

setwd("~/fmsc/EmpiricalExample/")

#Load packages
library(sem) #contains tsls routine

#Read the data. The value -999.999 is used to indicate missingness.
CGdata <- read.csv("Carstensen_Gundlach.csv", header = TRUE, na.strings = "-999.999", stringsAsFactors = FALSE)


#Rename columns that don't match the variable names from the paper
paper <- c("rule", "malfal", "exprop", "lngdpc", "trade", "latitude", "coast")
dataset <- c("kaufman", "mfalrisk", "exprop2", "lngdpc95", "frarom", "lat", "landsea")
key <- data.frame(paper, dataset, stringsAsFactors = FALSE)
rm(paper, dataset)

for(i in 1:nrow(key)){
  col <- which(names(CGdata) == key$dataset[i])
  names(CGdata)[col] <- key$paper[i]
}


#I use the FMSC to examine the instrument selection exercise in Table 2 of the paper. This table uses lngdpc as the dependent variable and rule and malfal as the independent variables throughout. The various entries in the table 

#This table uses rule and malfal as RHS variables and lngdpc as the outcome variable. The panels of the table look at how adding additional instruments changes the results.

#The instrument blocks considered are:
#     Baseline: lnmort, maleco
#     Climate:  frost, humid, latitude
#     Europe:   eurfrac, engfrac
#     Openness: coast, trade

#Note that there are some missing values in the dataset, so Table 2 is based on a subset including only 44 observations

CGdata <- subset(CGdata, !is.na(lngdpc) &
                         !is.na(rule) & !is.na(malfal) &
                         !is.na(lnmort) & !is.na(maleco) &   
                         !is.na(frost) & !is.na(humid) & 
                         !is.na(eurfrac) & !is.na(engfrac) & 
                         !is.na(coast) & !is.na(trade))


#For convenience, drop the columns we won't be using
keep <- c("lngdpc", "rule", "malfal", "maleco", "lnmort", "frost", "humid", "latitude", "eurfrac", "engfrac", "coast", "trade")
keep.cols <- which(names(CGdata) %in% keep)
CGdata <- CGdata[,keep.cols]

rm(keep, keep.cols)


#Function to extract quantities needed to replicate Table 1 of the paper from the tsls objects given above
reg.table <- function(tsls.object){
  coef <- tsls.object$coefficients
  SE <- sqrt(diag(tsls.object$V))
  N <- tsls.object$n
  z <- qt(0.975, N - length(coef))
  lower <- coef - z * SE
  upper <- coef + z * SE
  results <- round(rbind(coef, SE, lower, upper), 2) 
  return(results[,-1]) #Don't report intercept
}



model <- formula(lngdpc ~ rule + malfal)

#The numbers here correspond to numbered panels of the table
z1 

#Baseline instruments plus climate block: frost, humid, latitude
instruments1 <- tsls(model, ~ lnmort + maleco + frost + humid + latitude, CGdata)

#Baseline instruments plus Europe block: eurfrac, engfrac
instruments2 <- tsls(lngdpc ~ rule + malfal, ~ lnmort + maleco + eurfrac + engfrac, clean.data)

#Baseline instruments plus openness block: coast, trade
instruments3 <- tsls(lngdpc ~ rule + malfal, ~ lnmort + maleco + coast + trade, clean.data)

#All instruments
instruments4 <- tsls(lngdpc ~ rule + malfal, ~ lnmort + maleco + frost + humid + latitude + eurfrac + engfrac + coast + trade, clean.data)


#Summarize the results and replicate Table 2
instruments.results1 <- reg.table(instruments1)
instruments.results2 <- reg.table(instruments2)
instruments.results3 <- reg.table(instruments3)
instruments.results4 <- reg.table(instruments4)

cbind(instruments.results1, instruments.results2, instruments.results3, instruments.results4) #Matches Table 2 Perfectly!

#At the bottom of the Table are Andrews' (1999) GMM-BIC and GMM-HQ criteria for each of the instrument sets. To replicate these, we need the J-statistic which requires that we carry out efficient GMM rather than tsls. 

#Under homoscedasticity, tsls is efficient GMM, but I'm not sure if that's the assumption they're using here. Also, for the Andrews Criteria we need to used a centered covariance matrix.

#Might want to use some of the code from my simulation study here...
#Alternatively, could extract the objects generated by gmm to create a centered covariance matrix manually
#Probably can assume iid covariance matrix...

#Create blocks of instruments to feed to the function gmm
attach(clean.data)
baseline <- cbind(lnmort, maleco)
openness <- cbind(trade, coast)
climate <- cbind(frost, humid, latitude)
europe <- cbind(eurfrac, engfrac)
detach(clean.data)


#Full.data <- na.omit(data.frame(lngdpc = clean.data$lngdpc, rule = clean.data$rule, malfal = clean.data$malfal, baseline, europe))
#constant <- rep(1, NROW(Full.data))
#y <- Full.data[,1]
#X <- data.frame(constant, Full.data[,2:3])
#All exogenous regressors go in the instrument set: here only the constant
#Z.valid <- data.frame(constant, Full.data[,4:5])
#Z.additional <- data.frame(Full.data[,6:7])
#X <- as.matrix(X)
#Z.valid <- as.matrix(Z.valid)
#Z.additional <- as.matrix(Z.additional)



#-------------------------------------------------------#
#                  Replicate Table 3                    #
#-------------------------------------------------------#

#This table aims to assess the validity of the instruments lnmort and maleco

#Part of this involves using other instruments to identify the model and seeing the result. Are these instruments considered more likely to be valid? Which are they?



#-------------------------------------------------------#
#                     My Additions                      #
#-------------------------------------------------------#

#What about using squared terms or interactions of the regressors themselves as instruments? These will be valid instruments under the assumption that there are no nonlinear effects of the regressors. 

#Perhaps work with the baseline specification since there's no evidence of weak instruments in this case according to the Cragg-Donald statistic from the paper.

#Need to decide on a set of instruments to assume valid. Should it be the baseline instruments? The others? Need to make sure that my baseline instruments aren't weak since my method doesn't address weak instruments.


#Is rule^2 a strong instrument for rule?
attach(clean.data)

x <- rule[!is.na(rule) & !is.na(malfal)]
cor(x, x^2) #0.556 very strong!
cor(x, x^3) #0.891 extremely strong!

#How about malfal?
z <- malfal[!is.na(rule) & !is.na(malfal)]
cor(z, z^2) #0.978 extremely strong! Probably too strong in fact. Ah, this is because so many of the values are zero or one, and zero and one both equal their squares! In contrast, x is a continuous variable

#Interactions?
cor(x, z*x) #0.61 
cor(z, z*x) #-0.72


my.reg1 <- tsls(lngdpc ~ rule + malfal, ~ lnmort + maleco + rule^2 + rule * malfal, clean.data)

my.reg2 <- tsls(lngdpc ~ rule + malfal, ~ rule^2 + rule * malfal, clean.data)

reg.table(my.reg1)
reg.table(my.reg2)


summary(lm(lngdpc ~ rule + malfal))

detach(clean.data)
