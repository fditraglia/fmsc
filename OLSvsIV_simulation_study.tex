%!TEX root = main.tex
\section{Simulation Results}
\label{sec:simulations}
\subsection{OLS versus TSLS Example}
\label{sec:OLSvsIVsim}
I begin by examining the performance of the FMSC and averaging estimator in the OLS versus TSLS example.
All calculations in this section are based on the formulas from Sections \ref{sec:OLSvsIVExample} and \ref{sec:momentavgexample} with 10,000 simulation replications. 
The data generating process is given by 
\begin{eqnarray}
	y_i &=& 0.5 x_i + \epsilon_i\\
	\label{eq:OLSvsIVDGP1}
	x_i &=& \pi(z_{1i} + z_{2i} + z_{3i}) + v_i
	\label{eq:OLSvsIVDGP2}
\end{eqnarray}
with $(\epsilon_i, v_i, z_{1i}, z_{2i}, z_{3i}) \sim \mbox{ iid } N(0, \mathcal{S})$
\begin{equation}
	\mathcal{S} = \left[ \begin{array}
		{cc} \mathcal{S}_1 & 0 \\ 0 & \mathcal{S}_2
	\end{array} \right], \quad 
	\mathcal{S}_1 = \left[ \begin{array}
		{cc} 1 & \rho \\ \rho & 1 - \pi^2 
	\end{array} \right], \quad \mathcal{S}_2 = I_3 / 3
	\label{eq:OLSvsIVDGP3}
\end{equation}
for $i= 1, \hdots, N$ where $N$, $\rho$ and $\pi$ vary over a grid.
The goal is to estimate the effect of $x$ on $y$, in this case 0.5, with minimum MSE either by choosing between OLS and TSLS estimators or by averaging them.
To ensure that the finite-sample MSE of the TSLS estimator exists, this DGP includes three instruments leading to two overidentifying restrictions \citep{Phillips1980}.\footnote{Alternatively, one could use fewer instruments in the DGP and use work with trimmed MSE, as described in Appendix \ref{append:trim}.}
This design satisfies regularity conditions that are sufficient for Theorem \ref{thm:OLSvsIV} -- in particular it satisfies Assumption \ref{assump:OLSvsIV} -- and keeps the variance of $x$ fixed at one so that $\pi = Cor(x_i, z_{1i} + z_{2i} + z_{3i})$ and $\rho = Cor(x_i,\epsilon_i)$.
The first-stage R-squared is simply $1 - \sigma_v^2/\sigma_x^2 = \pi^2$ so that larger values of $|\pi|$ \emph{reduce} the variance of the TSLS estimator.
Since $\rho$ controls the endogeneity of $x$, larger values of $|\rho|$ \emph{increase} the bias of the OLS estimator.

Figure \ref{fig:OLSvsIV_RMSEbaseline} compares the root mean-squared error (RMSE) of the post-FMSC estimator to those of the OLS and TSLS estimators.\footnote{Note that, while the first two moments of the TSLS estimator exist in this simulation design, none of its higher moments do.
This can be seend from the simulation results: even with 10,000 replications, the RMSE of the TSLS estimator shows a noticeable degree of simulation error.}
For any values of $N$ and $\pi$ there is a value of $\rho$ below which OLS outperforms TSLS: as $N$ and $\pi$ increase this value approaches zero; as they decrease it approaches one.
In practice, of course, $\rho$ in unknown so we cannot tell which of OLS and TSLS is to be preferred \emph{a priori}.
If we make it our policy to always use TSLS we will protect ourselves against bias at the potential cost of very high variance.
On the other hand, we make it our policy to always use OLS we protect ourselves against high variance at the potential cost of severe bias. 
FMSC represents a compromise between these two extremes that does not require advance knowledge of $\rho$. 
When the RMSE of TSLS is high, the FMSC behaves more like OLS; when the RMSE of OLS is high it behaves more like TSLS.
Because the FMSC is itself a random variable, however, it sometimes makes moment selection mistakes.\footnote{For more discussion of this point, see Section \ref{sec:avg}.} 
For this reason it does not attain an RMSE equal to the lower envelope of the OLS and TSLS estimators.
The larger the RMSE difference between OLS and TSLS, however, the closer the FMSC comes to this lower envelope: costly mistakes are rare.


\begin{figure}
\centering
	\input{./SimulationOLSvsIV/Results/RMSE_coarse_pi_baseline.tex}
	\caption{RMSE values for the two-stage least squares (TSLS) estimator, the ordinary least squares (OLS) estimator, and the post-Focused Moment Selection Criterion (FMSC) estimator based on 10,000 simulation draws from the DGP given in Equations \ref{eq:OLSvsIVDGP1}--\ref{eq:OLSvsIVDGP3} using the formulas described in Section \ref{sec:OLSvsIVExample}.}
	\label{fig:OLSvsIV_RMSEbaseline}
\end{figure}

As shown above, the FMSC takes a very special form in this example: it is equivalent to a DHW test with $\alpha \approx 0.16$.
Accordingly, Figure \ref{fig:OLSvsIV_AVG} compares the RMSE of the post-FMSC estimator to those of DHW pre-test estimators with significance levels $\alpha = 0.05$ and $\alpha = 0.1$, indicated in the legend by DHW95 and DHW90.
Since these three procedures differ only in their critical values, they show similar qualitative behavior.
When $\rho$ is sufficiently close to zero, we saw from Figure \ref{fig:OLSvsIV_RMSEbaseline} that OLS has a lower RMSE than TSLS.
Since DHW95 and DHW90 require a higher burden of proof to reject OLS in favor of TSLS, they outperform FMSC in this region of the parameter space.
When $\rho$ crosses the threshold beyond which TSLS has a lower RMSE than OLS, the tables are turned: FMSC outperforms DHW95 and DHW90.
As $\rho$ increases further, relative to sample size and $\pi$, the three procedures become indistinguishable in terms of RMSE.
In addition to comparing the FMSC to DHW pre-test estimators, Figure \ref{fig:OLSvsIV_AVG} also presents the finite-sample RMSE of the minimum-AMSE moment average estimator presented in Equations \ref{eq:OLSvsIV_AVG1} and \ref{eq:OLSvsIV_AVG2}.
The performance of the moment average estimator is very strong: it provides the lowest worst-case RMSE and improves uniformly on the FMSC for all but the largest values of $\rho$.


\begin{figure}
\centering
	\input{./SimulationOLSvsIV/Results/RMSE_coarse_pi_relative_all.tex}
	\caption{RMSE values for the post-Focused Moment Selection Criterion (FMSC) estimator, Durbin-Hausman-Wu pre-test estimators with $\alpha = 0.1$ (DWH90) and $\alpha = 0.05$ (DHW95), and the minmum-AMSE averaging estimator, based on 10,000 simulation draws from the DGP given in Equations \ref{eq:OLSvsIVDGP1}--\ref{eq:OLSvsIVDGP3} using the formulas described in Sections \ref{sec:OLSvsIVExample} and \ref{sec:momentavgexample}.}
	\label{fig:OLSvsIV_AVG}
\end{figure}

Because this example involves a scalar target parameter, no selection or averaging scheme can provide a \emph{uniform} improvement over the minimax estimator, namely TSLS. 
But the cost of protection against the worst case is extremely poor performance when $\pi$ and $N$ are small.
When this is the case, there is a strong argument for preferring the FMSC or minimum-AMSE estimator: we can reap the benefits of OLS when $\rho$ is small without risking the extremely large biases that could result if $\rho$ is in fact large.
