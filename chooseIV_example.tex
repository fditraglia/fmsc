%!TEX root = main.tex
\subsection{Choosing Instrumental Variables Example}
\label{sec:chooseIVexample}
The OLS versus TSLS example is really a special case of instrument selection: if $x$ is exogenous, it is clearly ``its own best instrument.'' 
Viewed from this perspective, the FMSC amounted to trading off endogeneity against instrument strength. I now consider instrument selection \emph{in general} for linear GMM estimators in an iid setting. 
Consider the following model:
\begin{eqnarray}
    y_i &=& \mathbf{x}_i' \beta +  \epsilon_i\\
    \mathbf{x}_i &=&  \Pi_1' \mathbf{z}_{i}^{(1)} + \Pi_2'\mathbf{z}_{i}^{(2)} + \mathbf{v}_i
\end{eqnarray}
where $y$ is an outcome of interest, $\mathbf{x}$ is an $r$-vector of regressors, some of which are endogenous, $\mathbf{z}^{(1)}$ is a $p$-vector of instruments known to be exogenous, and $\mathbf{z}^{(2)}$ is a $q$-vector  of \emph{potentially endogenous} instruments. 
The $r$-vector $\beta$, $p\times r$ matrix $\Pi_1$, and $q\times r$ matrix $\Pi_2$ contain unknown constants. Stacking observations in the usual way, let $\mathbf{y}' = (y_1, \hdots, y_n)$, $X' = (\mathbf{x}_1, \hdots, \mathbf{x}_n)$, $\boldsymbol{\epsilon} = (\epsilon_1, \hdots, \epsilon_n)$, 
$Z_1' = (\mathbf{z}_{1}^{(1)}, \hdots, \mathbf{z}_{n}^{(1)})$, $Z_2' = (\mathbf{z}_{1}^{(2)}, \hdots, \mathbf{z}_{n}^{(2)})$, and $V' = (\mathbf{v}_1, \hdots, \mathbf{v}_n)$ where $n$ is the sample size.
Using this notation, $\mathbf{y} = X\beta +\boldsymbol{\epsilon}$ and $X =  Z \Pi + V$, where $Z = (Z_1, Z_2)$ and $\Pi = (\Pi_1', \Pi_2')'$. 

The idea behind this setup is that the instruments contained in $Z_2$ are expected to be strong. 
If we were confident that they were exogenous, we would certainly use them in estimation. 
Yet the very fact that we expect them to be strongly correlated with $\mathbf{x}$ gives us reason to fear that they may be endogenous. 
The exact opposite is true of $Z_1$: these are the instruments that we are prepared to assume are exogenous. 
But when is such an assumption plausible? Precisely when the instruments contained in $Z_1$ are \emph{not especially strong}. 
Accordingly, the FMSC attempts to trade off a small increase in bias from using a \emph{slightly} endogenous instrument against a larger decrease in variance from increased instrument strength.
To this end, consider a general linear GMM estimator of the form
$$\widehat{\beta}_S = (X'Z_S \widetilde{W}_S Z_S' X)^{-1}X'Z_S \widetilde{W}_S  Z_S' \mathbf{y}$$
where $S$ indexes the instruments used in estimation, $Z_S'  = \Xi_S Z'$ is the matrix containing only those instruments included in $S$, $|S|$ is the number of instruments used in estimation and $\widetilde{W}_S$ is an $|S|\times|S|$ positive definite weighting matrix. 
The following low-level conditions are sufficient for the asymptotic normality of $\widehat{\beta}_S$.

\begin{assump}[Choosing IVs]
\label{assump:chooseIV} 
	Let $\{(\mathbf{z}_{ni}, \mathbf{v}_{ni}, \epsilon_{ni})\colon 1\leq i \leq n, n = 1, 2, \hdots\}$ be a triangular array of random variables with $\mathbf{z}_{ni} = (\mathbf{z}_{ni}^{(1)}$, $\mathbf{z}_{ni}^{(1)})$ such that
	\begin{enumerate}[(a)]
		\item $(\mathbf{z}_{ni}, \mathbf{v}_{ni}, \epsilon_{ni}) \sim$ iid within each row of the array (i.e.\ for fixed $n$)
		\item $E[\mathbf{v}_{ni}\mathbf{z}_{ni}']=\mathbf{0}$, $E[\mathbf{z}^{(1)}_{ni} \epsilon_{ni}]=\mathbf{0}$, and $E[\mathbf{z}^{(2)}_{ni} \epsilon_{ni}] = \boldsymbol{\tau}/\sqrt{n}$ for all $n$
		\item $E[\left|\mathbf{z}_{ni}\right|^{4+\eta}] <C$, $E[\left|\epsilon_{ni}\right|^{4+\eta}] <C$, and $E[\left|\mathbf{v}_{ni}\right|^{4+\eta}] <C$ for some $\eta >0$, $C <\infty$
		\item $E[\mathbf{z}_{ni} \mathbf{z}_{ni}'] \rightarrow Q>0$ and $E[\epsilon_{ni}^2 \mathbf{z}_{ni} \mathbf{z}_{ni}'] \rightarrow \Omega >0$ as $n\rightarrow \infty$
		\item $\mathbf{x}_{ni} =  \Pi_1' \mathbf{z}_{ni}^{(1)} + \Pi_2'\mathbf{z}_{ni}^{(2)} + \mathbf{v}_{ni}$ where $\Pi_1 \neq \mathbf{0}$, $\Pi_2 \neq \mathbf{0}$, and $y_i = \mathbf{x}_{ni}' \beta +  \epsilon_{ni}$
	\end{enumerate}
\end{assump}

The preceding conditions are similar to although more general than those contained in Assumption \ref{assump:OLSvsIV}. 
Although I no longer assume homoskedasticity, for simplicity I retain the assumption that the triangular array is iid in each row. 

\begin{thm}[Choosing IVs Limit Distribution]
\label{thm:chooseIV} Suppose that $\widetilde{W}_S \rightarrow_p W_S >0$. Then, under Assumption \ref{assump:chooseIV}
$$\sqrt{n}\left(\widehat{\beta}_S - \beta \right) \overset{d}{\rightarrow} -K_S \Xi_S \left(\left[\begin{array}
           {c} \mathbf{0} \\ \boldsymbol{\tau}
         \end{array}\right] + M \right)$$
where
         $$-K_S = \left(\Pi' Q_S W_S Q_S'\Pi\right)^{-1} \Pi'Q_SW_S$$
$M \sim N(\mathbf{0}, \Omega)$, $Q_S = Q \Xi_S'$, and $Q$ and $\Omega$ are defined in Assumption \ref{assump:chooseIV}.
\end{thm}
To implement the FMSC for this example, we simply need to specialize Equation \ref{eq:fmsc}.
To simplify the notation, let
\begin{equation}
\label{eq:xi12}
\Xi_1 = \left[\begin{array}{cc} I_{p} & 0_{p \times q}  \end{array}\right], \quad
    \Xi_2 = \left[ \begin{array}{cc}
              0_{q \times p}& I_{q}
            \end{array}\right]	
\end{equation}
where $0_{m\times n}$ denotes an $m\times n$ matrix of zeros and $I_m$ denotes the $m\times m$ identity matrix.
Using this convention, $Z_1 = Z \Xi_1'$ and $Z_2 = Z \Xi_2'$.
In this example the valid estimator, defined in Assumption \ref{assump:Identification}, is given by
\begin{equation}
\label{eq:betav}
\widehat{\beta}_v = \left(X'Z_1 \widetilde{W}_v Z_1' X\right)^{-1}X'Z_1 \widetilde{W}_v Z_1' \mathbf{y}	
\end{equation}
and we estimate $\nabla_\beta \mu(\beta)$ with $\nabla_\beta \mu(\widehat{\beta}_v)$.  
Similarly, 
$$-\widehat{K}_S = n\left(X'Z \Xi_S' \widetilde{W}_S \Xi_S Z' X\right)^{-1}X' Z \Xi_S' \widetilde{W}_S$$
is the natural consistent estimator of $-K_S$ in this setting.\footnote{The negative sign is squared in the FMSC expression and hence disappears. I write it here only to be consistent with the notation of Theorem \ref{thm:normality}.}
Since $\Xi_S$ is known, the only remaining quantities from Equation \ref{eq:fmsc} are $\widehat{\boldsymbol{\tau}}$, $\widehat{\Psi}$ and $\widehat{\Omega}$. 
The following result specializes Theorem \ref{thm:tau} to the present example.
\begin{thm}
Let $\widehat{\boldsymbol{\tau}} = n^{-1/2} Z_2' ( \mathbf{y} - X\widehat{\beta}_v)$ where $\widehat{\beta}_v$ is as defined in Equation \ref{eq:betav}. Under Assumption \ref{assump:chooseIV} we have
$\widehat{\boldsymbol{\tau}} \rightarrow_d \boldsymbol{\tau} + \Psi M$
where $M$ is defined in Theorem \ref{thm:chooseIV},
\begin{eqnarray*}
	\Psi &=&\left[ \begin{array}{cc}-\Xi_2Q \Pi K_v  & I_{q} \end{array}\right] \\
	-K_v &=& \left(\Pi' Q \Xi'_1 W_v \Xi_1 Q'\Pi\right)^{-1} \Pi'Q \Xi_1' W_v
\end{eqnarray*}
$W_v$ is the probability limit of the weighting matrix from Equation \ref{eq:betav}, $I_q$ is the $q\times q$ identity matrix, $\Xi_1$ is defined in Equation \ref{eq:xi12},  and $Q$ is defined in Assumption \ref{assump:chooseIV}.
\end{thm}
Using this result, I construct the asymptotically unbiased estimator $\widehat{\tau}\widehat{\tau}' - \widehat{\Psi}\widehat{\Omega} \widehat{\Psi}'$ of $\tau\tau'$ from
	$$\widehat{\Psi} = \left[ \begin{array}
		{cc}
		-n^{-1}Z_2'X \left(-\widehat{K}_v\right) & I_q
	\end{array}\right], \quad -\widehat{K}_v = n\left(X'Z_1 \widetilde{W}_v Z_1' X\right)^{-1}X'Z_1 \widetilde{W}_v$$

All that remains before substituting values into Equation \ref{eq:fmsc} is to estimate $\Omega$. 
There are many possible ways to proceed, depending on the problem at hand and the assumptions one is willing to make. 
In the simulation and empirical examples discussed below I examine the TSLS estimator, that is $\widetilde{W}_S = (\Xi_S Z'Z\Xi_S)^{-1}$, and estimate $\Omega$ as follows. 
For all specifications \emph{except} the valid estimator $\widehat{\beta}_v$, I employ the centered, heteroskedasticity-consistent estimator
\begin{equation}
	\widehat{\Omega}_S = \frac{1}{n}\sum_{i=1}^n u_i(\widehat{\beta}_S)^2\mathbf{z}_{iS} \mathbf{z}_{iS}'  - \left(\frac{1}{n}\sum_{i=1}^n u_i(\widehat{\beta}_S)\mathbf{z}_{iS}   \right)\left(\frac{1}{n}\sum_{i=1}^n  u_i(\widehat{\beta}_S)\mathbf{z}_{iS}'  \right)
\end{equation}
where $u_i(\beta) = y_i - \mathbf{x}_i'\beta$, $\widehat{\beta}_S = (X'Z_S(Z_S'Z_S)^{-1}Z_S'X)^{-1}X'Z_S(Z_S'Z_S)^{-1}Z_S'\mathbf{y}$, $\mathbf{z}_{iS} = \Xi_S \mathbf{z}_i$ and $Z_S' = \Xi_S Z'$.
Centering allows moment functions to have non-zero means. 
While the local mis-specification framework implies that these means tend to zero in the limit, they are non-zero for any fixed sample size. 
Centering accounts for this fact, and thus provides added robustness. 
Since the valid estimator $\widehat{\beta}_v$ has no asymptotic bias, the AMSE of any target parameter based on this estimator equals its asymptotic variance. 
Accordingly, I use 
\begin{equation}
	\widetilde{\Omega}_{11}= n^{-1}\sum_{i=1}^n u_i(\widehat{\beta}_v)^2\mathbf{z}_{1i}\mathbf{z}_{1i}'
\end{equation}
rather than the $(p\times p)$ upper left sub-matrix of $\widehat{\Omega}$ to estimate this quantity. 
This imposes the assumption that all instruments in $Z_1$ are valid so that no centering is needed, providing greater precision.