%!TEX root = main.tex
\subsection{Choosing Instrumental Variables Example}
\label{sec:chooseIVexample}
The OLS versus TSLS example is really a special case of instrument selection: if $x$ is exogenous, it is clearly ``its own best instrument.'' 
Viewed from this perspective, the FMSC amounts to trading off endogeneity against instrument strength. I now consider instrument selection in general for linear GMM estimators in an iid setting. 
Consider the  model:
\begin{eqnarray}
  y_{ni} &=& \mathbf{x}_{ni}' \beta +  \epsilon_{ni}\\
    \mathbf{x}_{ni} &=&  \Pi_1' \mathbf{z}_{ni}^{(1)} + \Pi_2'\mathbf{z}_{ni}^{(2)} + \mathbf{v}_{ni}
\end{eqnarray}
where $y$ is an outcome of interest, $\mathbf{x}$ is an $r$-vector of regressors, some of which are endogenous, $\mathbf{z}^{(1)}$ is a $p$-vector of instruments known to be exogenous, and $\mathbf{z}^{(2)}$ is a $q$-vector  of \emph{potentially endogenous} instruments. 
The $r$-vector $\beta$, $p\times r$ matrix $\Pi_1$, and $q\times r$ matrix $\Pi_2$ contain unknown constants. Stacking observations in the usual way, we can write the system in matrix form as $\mathbf{y} = X\beta +\boldsymbol{\epsilon}$ and $X =  Z \Pi + V$, where $Z = (Z_1, Z_2)$ and $\Pi = (\Pi_1', \Pi_2')'$. 

In this example, the idea is that the instruments contained in $Z_2$ are expected to be strong.
If we were confident that they were exogenous, we would certainly use them in estimation. 
Yet the very fact that we expect them to be strongly correlated with $\mathbf{x}$ gives us reason to fear that they may be endogenous. 
The exact opposite is true of $Z_1$: these are the instruments that we are prepared to assume are exogenous. 
But when is such an assumption plausible? Precisely when the instruments contained in $Z_1$ are \emph{not especially strong}. 
Accordingly, the FMSC attempts to trade off a small increase in bias from using a \emph{slightly} endogenous instrument against a larger decrease in variance from increased instrument strength.
To this end, consider a general linear GMM estimator of the form
$$\widehat{\beta}_S = (X'Z_S \widetilde{W}_S Z_S' X)^{-1}X'Z_S \widetilde{W}_S  Z_S' \mathbf{y}$$
where $S$ indexes the instruments used in estimation, $Z_S'  = \Xi_S Z'$ is the matrix containing only those instruments included in $S$, $|S|$ is the number of instruments used in estimation and $\widetilde{W}_S$ is an $|S|\times|S|$ positive definite weighting matrix. 


\begin{thm}[Choosing IVs Limit Distribution]
\label{thm:chooseIV} 
Let $(\mathbf{z}_{ni}, v_{ni}, \epsilon_{ni})$ be a triangular array of random variables such that $E[\mathbf{z}_{ni} \epsilon_{ni}]=\mathbf{0}$, $E[\mathbf{z}_{ni} v_{ni}]=\mathbf{0}$, and $E[\epsilon_{ni}v_{ni}] = \tau/\sqrt{n}$ for all $n$. Suppose further that $\widetilde{W}_S \rightarrow_p W_S >0$. 
Then, under standard regularity conditions, e.g.\ Assumption \ref{assump:chooseIV} in Online Appendix \ref{sec:sufficient_conditions}, 
$$\sqrt{n}\left(\widehat{\beta}_S - \beta \right) \overset{d}{\rightarrow} -K_S \Xi_S \left(\left[\begin{array}
           {c} \mathbf{0} \\ \boldsymbol{\tau}
         \end{array}\right] + M \right)$$
where
         $$-K_S = \left(\Pi' Q_S W_S Q_S'\Pi\right)^{-1} \Pi'Q_SW_S$$
$M \sim N(\mathbf{0}, \Omega)$, $Q_S = Q \Xi_S'$, $E[\mathbf{z}_{ni} \mathbf{z}_{ni}'] \rightarrow Q$ and $E[\epsilon_{ni}^2 \mathbf{z}_{ni} \mathbf{z}_{ni}'] \rightarrow \Omega$ as $n\rightarrow \infty$
\end{thm}
To implement the FMSC for this example, we simply need to specialize Equation \ref{eq:fmsc}.
To simplify the notation, let
\begin{equation}
\label{eq:xi12}
\Xi_1 = \left[\begin{array}{cc} \mathbf{I}_{p} & 0_{p \times q}  \end{array}\right], \quad
    \Xi_2 = \left[ \begin{array}{cc}
        0_{q \times p}& \mathbf{I}_{q}
            \end{array}\right]	
\end{equation}
where $0_{p\times q}$ denotes a $p\times q$ matrix of zeros and $\mathbf{I}_q$ denotes the $q\times q$ identity matrix.
Using this convention, $Z_1 = Z \Xi_1'$ and $Z_2 = Z \Xi_2'$.
In this example the valid estimator, defined in Assumption \ref{assump:Identification}, is given by
\begin{equation}
\label{eq:betav}
\widehat{\beta}_v = \left(X'Z_1 \widetilde{W}_v Z_1' X\right)^{-1}X'Z_1 \widetilde{W}_v Z_1' \mathbf{y}	
\end{equation}
and we estimate $\nabla_\beta \mu(\beta)$ with $\nabla_\beta \mu(\widehat{\beta}_v)$.  
Similarly, 
$$-\widehat{K}_S = n\left(X'Z \Xi_S' \widetilde{W}_S \Xi_S Z' X\right)^{-1}X' Z \Xi_S' \widetilde{W}_S$$
is the natural consistent estimator of $-K_S$ in this setting.\footnote{The negative sign is squared in the FMSC expression and hence disappears. I write it here only to be consistent with the notation of Theorem \ref{thm:normality}.}
Since $\Xi_S$ is known, the only remaining quantities from Equation \ref{eq:fmsc} are $\widehat{\boldsymbol{\tau}}$, $\widehat{\Psi}$ and $\widehat{\Omega}$. 
The following result specializes Theorem \ref{thm:tau} to the present example.
\begin{thm}
Let $\widehat{\boldsymbol{\tau}} = n^{-1/2} Z_2' ( \mathbf{y} - X\widehat{\beta}_v)$ where $\widehat{\beta}_v$ is as defined in Equation \ref{eq:betav}. Under the conditions of Theorem \ref{thm:chooseIV} we have
$\widehat{\boldsymbol{\tau}} \rightarrow_d \boldsymbol{\tau} + \Psi M$
where $M$ is defined in Theorem \ref{thm:chooseIV},
\begin{eqnarray*}
	\Psi &=&\left[ \begin{array}{cc}-\Xi_2Q \Pi K_v  & I_{q} \end{array}\right] \\
	-K_v &=& \left(\Pi' Q \Xi'_1 W_v \Xi_1 Q'\Pi\right)^{-1} \Pi'Q \Xi_1' W_v
\end{eqnarray*}
$W_v$ is the probability limit of the weighting matrix from Equation \ref{eq:betav}, $I_q$ is the $q\times q$ identity matrix, $\Xi_1$ is defined in Equation \ref{eq:xi12}, and $E[\mathbf{z}_{ni} \mathbf{z}_{ni}'] \rightarrow Q$. 
\end{thm}
Using this result, I construct the asymptotically unbiased estimator $\widehat{\tau}\widehat{\tau}' - \widehat{\Psi}\widehat{\Omega} \widehat{\Psi}'$ of $\tau\tau'$ from
	$$\widehat{\Psi} = \left[ \begin{array}
		{cc}
		-n^{-1}Z_2'X \left(-\widehat{K}_v\right) & I_q
	\end{array}\right], \quad -\widehat{K}_v = n\left(X'Z_1 \widetilde{W}_v Z_1' X\right)^{-1}X'Z_1 \widetilde{W}_v$$

All that remains before substituting values into Equation \ref{eq:fmsc} is to estimate $\Omega$. 
In the simulation and empirical examples discussed below I examine the TSLS estimator, that is $\widetilde{W}_S = (\Xi_S Z'Z\Xi_S)^{-1}$, and estimate $\Omega$ as follows. 
For all specifications \emph{except} the valid estimator $\widehat{\beta}_v$, I employ the centered, heteroskedasticity-consistent estimator
\begin{equation}
	\widehat{\Omega}_S = \frac{1}{n}\sum_{i=1}^n u_i(\widehat{\beta}_S)^2\mathbf{z}_{iS} \mathbf{z}_{iS}'  - \left(\frac{1}{n}\sum_{i=1}^n u_i(\widehat{\beta}_S)\mathbf{z}_{iS}   \right)\left(\frac{1}{n}\sum_{i=1}^n  u_i(\widehat{\beta}_S)\mathbf{z}_{iS}'  \right)
\end{equation}
where $u_i(\beta) = y_i - \mathbf{x}_i'\beta$, $\widehat{\beta}_S = (X'Z_S(Z_S'Z_S)^{-1}Z_S'X)^{-1}X'Z_S(Z_S'Z_S)^{-1}Z_S'\mathbf{y}$, $\mathbf{z}_{iS} = \Xi_S \mathbf{z}_i$ and $Z_S' = \Xi_S Z'$.
Centering allows moment functions to have non-zero means. 
While the local mis-specification framework implies that these means tend to zero in the limit, they are non-zero for any fixed sample size. 
Centering accounts for this fact, and thus provides added robustness. 
Since the valid estimator $\widehat{\beta}_v$ has no asymptotic bias, the AMSE of any target parameter based on this estimator equals its asymptotic variance. 
Accordingly, I use 
\begin{equation}
	\widetilde{\Omega}_{11}= n^{-1}\sum_{i=1}^n u_i(\widehat{\beta}_v)^2\mathbf{z}_{1i}\mathbf{z}_{1i}'
\end{equation}
rather than the $(p\times p)$ upper left sub-matrix of $\widehat{\Omega}$ to estimate this quantity. 
This imposes the assumption that all instruments in $Z_1$ are valid so that no centering is needed, providing greater precision.
